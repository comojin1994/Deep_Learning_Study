{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vanila_RNN_LSTM_GRU.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMjgfJh4RCkk7TGCDwfvPFA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comojin1994/Deep_Learning_Study/blob/master/3step_lecture/Vanila_RNN_LSTM_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ynq7ownobFbU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "41509936-8445-4cb0-fd2f-94c1eebab65b"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r0uO0RDdN47",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkLIfVomdSl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 10\n",
        "NUM_WORDS = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43lib8qudarb",
        "colab_type": "text"
      },
      "source": [
        "### RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2bZLL4VdcCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(RNN, self).__init__()\n",
        "        ### NUM_WORDS만큼의 one-hot vector를 16dim의 벡터로 변환\n",
        "        self.emb = tf.keras.layers.Embedding(NUM_WORDS, 16)\n",
        "        self.rnn = tf.keras.layers.SimpleRNN(32)\n",
        "        self.dense = tf.keras.layers.Dense(2, activation='softmax')\n",
        "\n",
        "    def call(self, x, training=False, mask=None):\n",
        "        x = self.emb(x)\n",
        "        x = self.rnn(x)\n",
        "        return self.dense(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb-ymTwzk_x9",
        "colab_type": "text"
      },
      "source": [
        "### LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw2W5r8-lC5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.emb = tf.keras.layers.Embedding(NUM_WORDS, 16)\n",
        "        self.lstm = tf.keras.layers.LSTM(32)\n",
        "        self.dense = tf.keras.layers.Dense(2, activation='softmax')\n",
        "\n",
        "    def call(self, x, training=False, mask=None):\n",
        "        x = self.emb(x)\n",
        "        x = self.lstm(x)\n",
        "        return self.dense(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3q9k9Dwmnqp",
        "colab_type": "text"
      },
      "source": [
        "### GRU Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f42FgGB5mpUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRU(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(GRU, self).__init__()\n",
        "        self.emb = tf.keras.layers.Embedding(NUM_WORDS, 16)\n",
        "        self.lstm = tf.keras.layers.GRU(32)\n",
        "        self.dense = tf.keras.layers.Dense(2, activation='softmax')\n",
        "\n",
        "    def call(self, x, training=False, mask=None):\n",
        "        x = self.emb(x)\n",
        "        x = self.lstm(x)\n",
        "        return self.dense(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk6CLqyddvxr",
        "colab_type": "text"
      },
      "source": [
        "### Train, Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFoEcpR3dxNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(model, inputs, labels, optimizer, loss_object, train_loss, train_accuracy):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def test_step(model, inputs, labels, loss_object, test_loss, test_accuracy):\n",
        "    predictions = model(inputs, training=False)\n",
        "    t_loss = loss_object(labels, predictions)\n",
        "\n",
        "    test_loss(t_loss)\n",
        "    test_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPq4Jy-cgash",
        "colab_type": "text"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ykhr7dOmgcVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### imdb 데이터 : 영화 리뷰에 대한 감성 분석\n",
        "### y가 0 / 1로 이루어져 있음\n",
        "imdb = tf.keras.datasets.imdb\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=NUM_WORDS)\n",
        "\n",
        "### padding : 'post', 'pre'\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        value=0,\n",
        "                                                        padding='pre',\n",
        "                                                        maxlen=32)\n",
        "\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                       maxlen=32,\n",
        "                                                       padding='pre',\n",
        "                                                       value=0)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34IoI_R-lqu5",
        "colab_type": "text"
      },
      "source": [
        "### **Vanila RNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpwkmOCVh-SF",
        "colab_type": "text"
      },
      "source": [
        "### Load Model, loss, optimizer, metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mfQDG3fiDvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_model = RNN()\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-6BS38xipbU",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eW1wbbVixDJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "3b8c22ab-d619-4d1d-fd51-2333358d717f"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    for seqs, labels in train_ds:\n",
        "        train_step(rnn_model, seqs, labels, optimizer, loss_object, train_loss, train_accuracy)\n",
        "\n",
        "    for test_seqs, test_labels in test_ds:\n",
        "        test_step(rnn_model, test_seqs, test_labels, loss_object, test_loss, test_accuracy)\n",
        "\n",
        "    template = 'Epoch {} Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "    print(template.format(\n",
        "          epoch + 1,\n",
        "          train_loss.result(),\n",
        "          train_accuracy.result()*100,\n",
        "          test_loss.result(),\n",
        "          test_accuracy.result()*100\n",
        "    ))\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss: 0.5461286306381226, Accuracy: 70.56800079345703, Test Loss: 0.46181321144104004, Test Accuracy: 78.28800201416016\n",
            "Epoch 2 Loss: 0.360223650932312, Accuracy: 84.14800262451172, Test Loss: 0.4842202961444855, Test Accuracy: 77.83599853515625\n",
            "Epoch 3 Loss: 0.22313256561756134, Accuracy: 91.34400177001953, Test Loss: 0.5924072861671448, Test Accuracy: 74.79199981689453\n",
            "Epoch 4 Loss: 0.09801386296749115, Accuracy: 96.69200134277344, Test Loss: 0.7976824045181274, Test Accuracy: 73.79999542236328\n",
            "Epoch 5 Loss: 0.04604891315102577, Accuracy: 98.54000091552734, Test Loss: 0.9864574670791626, Test Accuracy: 74.29199981689453\n",
            "Epoch 6 Loss: 0.021950941532850266, Accuracy: 99.33200073242188, Test Loss: 1.1732544898986816, Test Accuracy: 74.14800262451172\n",
            "Epoch 7 Loss: 0.015439605340361595, Accuracy: 99.52799987792969, Test Loss: 1.2891355752944946, Test Accuracy: 73.58000183105469\n",
            "Epoch 8 Loss: 0.019586259499192238, Accuracy: 99.38399505615234, Test Loss: 1.3166275024414062, Test Accuracy: 72.14800262451172\n",
            "Epoch 9 Loss: 0.02052386663854122, Accuracy: 99.2760009765625, Test Loss: 1.4505563974380493, Test Accuracy: 72.43599700927734\n",
            "Epoch 10 Loss: 0.012685743160545826, Accuracy: 99.59600067138672, Test Loss: 1.5670818090438843, Test Accuracy: 75.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj1Bs68qlvre",
        "colab_type": "text"
      },
      "source": [
        "## **LSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4n7DhN1lzc_",
        "colab_type": "text"
      },
      "source": [
        "### Load Model, loss, optimizer, metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y6jfGoHlxZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm_model = LSTM()\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cWJoNX-l4Bo",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWJrBzEXl5_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "7a495c8c-1659-4b8b-a85f-852668741fde"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    for seqs, labels in train_ds:\n",
        "        train_step(lstm_model, seqs, labels, optimizer, loss_object, train_loss, train_accuracy)\n",
        "\n",
        "    for test_seqs, test_labels in test_ds:\n",
        "        test_step(lstm_model, test_seqs, test_labels, loss_object, test_loss, test_accuracy)\n",
        "\n",
        "    template = 'Epoch {} Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "    print(template.format(\n",
        "          epoch + 1,\n",
        "          train_loss.result(),\n",
        "          train_accuracy.result()*100,\n",
        "          test_loss.result(),\n",
        "          test_accuracy.result()*100\n",
        "    ))\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss: 0.5028752088546753, Accuracy: 73.98399353027344, Test Loss: 0.43520388007164, Test Accuracy: 79.33599853515625\n",
            "Epoch 2 Loss: 0.37079429626464844, Accuracy: 83.49600219726562, Test Loss: 0.4555682837963104, Test Accuracy: 78.91999816894531\n",
            "Epoch 3 Loss: 0.31726810336112976, Accuracy: 86.3239974975586, Test Loss: 0.492877334356308, Test Accuracy: 78.2760009765625\n",
            "Epoch 4 Loss: 0.2678675949573517, Accuracy: 88.8759994506836, Test Loss: 0.5092926621437073, Test Accuracy: 77.95999908447266\n",
            "Epoch 5 Loss: 0.21883524954319, Accuracy: 91.2239990234375, Test Loss: 0.6740652918815613, Test Accuracy: 77.3759994506836\n",
            "Epoch 6 Loss: 0.17508773505687714, Accuracy: 93.21600341796875, Test Loss: 0.6611217856407166, Test Accuracy: 76.73600006103516\n",
            "Epoch 7 Loss: 0.1319689303636551, Accuracy: 94.85600280761719, Test Loss: 0.8110933303833008, Test Accuracy: 75.8759994506836\n",
            "Epoch 8 Loss: 0.10157676041126251, Accuracy: 96.31999969482422, Test Loss: 0.9797196984291077, Test Accuracy: 75.7040023803711\n",
            "Epoch 9 Loss: 0.07603815943002701, Accuracy: 97.2280044555664, Test Loss: 1.1390987634658813, Test Accuracy: 74.82799530029297\n",
            "Epoch 10 Loss: 0.05585373938083649, Accuracy: 97.98400115966797, Test Loss: 1.2516053915023804, Test Accuracy: 74.86000061035156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAK3Ju92nnIk",
        "colab_type": "text"
      },
      "source": [
        "## **GRU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84apD9Qvno6_",
        "colab_type": "text"
      },
      "source": [
        "### Load Model, loss, optimizer, metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9NurtR8ntGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru_model = GRU()\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14AWnou3ntsH",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQdcZYkDnvBv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "4a4e9ab7-4c9f-4743-d124-6a28a9c75b8f"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    for seqs, labels in train_ds:\n",
        "        train_step(gru_model, seqs, labels, optimizer, loss_object, train_loss, train_accuracy)\n",
        "\n",
        "    for test_seqs, test_labels in test_ds:\n",
        "        test_step(gru_model, test_seqs, test_labels, loss_object, test_loss, test_accuracy)\n",
        "\n",
        "    template = 'Epoch {} Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "    print(template.format(\n",
        "          epoch + 1,\n",
        "          train_loss.result(),\n",
        "          train_accuracy.result()*100,\n",
        "          test_loss.result(),\n",
        "          test_accuracy.result()*100\n",
        "    ))\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss: 0.5079026222229004, Accuracy: 73.63999938964844, Test Loss: 0.4441724121570587, Test Accuracy: 78.97599792480469\n",
            "Epoch 2 Loss: 0.37264707684516907, Accuracy: 83.36799621582031, Test Loss: 0.45184049010276794, Test Accuracy: 78.98400115966797\n",
            "Epoch 3 Loss: 0.3242509663105011, Accuracy: 86.1520004272461, Test Loss: 0.4839935004711151, Test Accuracy: 78.052001953125\n",
            "Epoch 4 Loss: 0.2758696973323822, Accuracy: 88.52799987792969, Test Loss: 0.4964955449104309, Test Accuracy: 77.46800231933594\n",
            "Epoch 5 Loss: 0.23409681022167206, Accuracy: 90.5999984741211, Test Loss: 0.6103373765945435, Test Accuracy: 77.0719985961914\n",
            "Epoch 6 Loss: 0.19673731923103333, Accuracy: 92.62800598144531, Test Loss: 0.6658809781074524, Test Accuracy: 76.56000518798828\n",
            "Epoch 7 Loss: 0.16458949446678162, Accuracy: 93.97600555419922, Test Loss: 0.7438694834709167, Test Accuracy: 75.94400024414062\n",
            "Epoch 8 Loss: 0.13424459099769592, Accuracy: 95.22000122070312, Test Loss: 0.8605367541313171, Test Accuracy: 75.84400177001953\n",
            "Epoch 9 Loss: 0.10569413751363754, Accuracy: 96.41199493408203, Test Loss: 1.0832704305648804, Test Accuracy: 74.87999725341797\n",
            "Epoch 10 Loss: 0.08107712864875793, Accuracy: 97.31600189208984, Test Loss: 1.172792911529541, Test Accuracy: 74.5199966430664\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
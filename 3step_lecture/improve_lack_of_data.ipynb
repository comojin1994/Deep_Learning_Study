{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "improve_lack_of_data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgbfpzx3bYG3w1T318x3ku",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comojin1994/Deep_Learning_Study/blob/master/3step_lecture/improve_lack_of_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdkj8mF8t6dq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "addfb775-2316-4e58-a89d-b8037a6a54a7"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "%matplotlib inline\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Fm1AZ7FuQyR",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1Yva9Q5ubDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzWRU7D1ub-z",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0uUf44Luf2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense1 = tf.keras.layers.Dense(1024, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    def call(self, x, training=False, mask=None):\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        return self.dense2(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhv-tCOFu2o7",
        "colab_type": "text"
      },
      "source": [
        "### Load Data(imbalance)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NLgKz7bu5qh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4a64ff33-1295-40bb-b325-6e2b153f7026"
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10 # 32x32x3\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# TODO: 학습 데이터를 Imbalanced small dataset으로 변형하기\n",
        "x_train_small = list()\n",
        "y_train_small = list()\n",
        "for x, y in zip(x_train, y_train):\n",
        "    if (y == 0 and random.randint(0, 100) < 10) or y == 1:\n",
        "        x_train_small.append(x[:])\n",
        "        y_train_small.append(y)\n",
        "\n",
        "x_test_small = list()\n",
        "y_test_small = list()\n",
        "for x, y in zip(x_test, y_test):\n",
        "    if y == 0 or y == 1:\n",
        "        x_test_small.append(x[:])\n",
        "        y_test_small.append(y)\n",
        "\n",
        "x_train = np.stack(x_train_small, axis=0)\n",
        "y_train = np.stack(y_train_small, axis=0)\n",
        "\n",
        "x_test = np.stack(x_test_small, axis=0)\n",
        "y_test = np.stack(y_test_small, axis=0)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(2048)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32).prefetch(2048)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdKUxRR4wraE",
        "colab_type": "text"
      },
      "source": [
        "### Training with imbalance data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoNPOCMVwumk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MyModel()\n",
        "\n",
        "loss_object = 'binary_crossentropy'\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "metrics = ['accuracy',\n",
        "           tf.keras.metrics.Precision(name='precision'),\n",
        "           tf.keras.metrics.Recall(name='recall')]\n",
        "model.compile(optimizer=optimizer, loss=loss_object, metrics=metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b235F-P5w_Iw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4e182962-d004-4172-c329-73ab3bff52fe"
      },
      "source": [
        "history = model.fit(train_ds,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=test_ds)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 172 steps, validate for 63 steps\n",
            "Epoch 1/100\n",
            "172/172 [==============================] - 3s 19ms/step - loss: 0.4653 - accuracy: 0.9032 - precision: 0.9187 - recall: 0.9804 - val_loss: 0.7737 - val_accuracy: 0.6030 - val_precision: 0.5582 - val_recall: 0.9880\n",
            "Epoch 2/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.2531 - accuracy: 0.9152 - precision: 0.9263 - recall: 0.9852 - val_loss: 0.6172 - val_accuracy: 0.7035 - val_precision: 0.6326 - val_recall: 0.9710\n",
            "Epoch 3/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.2302 - accuracy: 0.9205 - precision: 0.9323 - recall: 0.9840 - val_loss: 0.7496 - val_accuracy: 0.6355 - val_precision: 0.5796 - val_recall: 0.9870\n",
            "Epoch 4/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.2207 - accuracy: 0.9209 - precision: 0.9345 - recall: 0.9818 - val_loss: 0.7180 - val_accuracy: 0.6605 - val_precision: 0.5967 - val_recall: 0.9900\n",
            "Epoch 5/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.2075 - accuracy: 0.9274 - precision: 0.9398 - recall: 0.9832 - val_loss: 0.5481 - val_accuracy: 0.7490 - val_precision: 0.6732 - val_recall: 0.9680\n",
            "Epoch 6/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1969 - accuracy: 0.9296 - precision: 0.9430 - recall: 0.9820 - val_loss: 0.8430 - val_accuracy: 0.6385 - val_precision: 0.5814 - val_recall: 0.9890\n",
            "Epoch 7/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.2018 - accuracy: 0.9291 - precision: 0.9417 - recall: 0.9828 - val_loss: 1.1498 - val_accuracy: 0.5720 - val_precision: 0.5390 - val_recall: 0.9940\n",
            "Epoch 8/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1929 - accuracy: 0.9294 - precision: 0.9438 - recall: 0.9808 - val_loss: 0.9238 - val_accuracy: 0.6430 - val_precision: 0.5842 - val_recall: 0.9920\n",
            "Epoch 9/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1787 - accuracy: 0.9365 - precision: 0.9485 - recall: 0.9836 - val_loss: 0.5285 - val_accuracy: 0.7810 - val_precision: 0.7060 - val_recall: 0.9630\n",
            "Epoch 10/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1735 - accuracy: 0.9365 - precision: 0.9490 - recall: 0.9830 - val_loss: 0.7632 - val_accuracy: 0.6990 - val_precision: 0.6269 - val_recall: 0.9830\n",
            "Epoch 11/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1650 - accuracy: 0.9367 - precision: 0.9508 - recall: 0.9812 - val_loss: 0.4643 - val_accuracy: 0.8155 - val_precision: 0.7459 - val_recall: 0.9570\n",
            "Epoch 12/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1668 - accuracy: 0.9376 - precision: 0.9500 - recall: 0.9832 - val_loss: 0.4439 - val_accuracy: 0.8175 - val_precision: 0.7526 - val_recall: 0.9460\n",
            "Epoch 13/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1588 - accuracy: 0.9392 - precision: 0.9534 - recall: 0.9812 - val_loss: 0.4410 - val_accuracy: 0.8250 - val_precision: 0.7604 - val_recall: 0.9490\n",
            "Epoch 14/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1614 - accuracy: 0.9422 - precision: 0.9553 - recall: 0.9824 - val_loss: 0.5977 - val_accuracy: 0.7690 - val_precision: 0.6908 - val_recall: 0.9740\n",
            "Epoch 15/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1473 - accuracy: 0.9454 - precision: 0.9576 - recall: 0.9836 - val_loss: 0.5173 - val_accuracy: 0.8040 - val_precision: 0.7275 - val_recall: 0.9720\n",
            "Epoch 16/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1474 - accuracy: 0.9432 - precision: 0.9580 - recall: 0.9806 - val_loss: 0.7019 - val_accuracy: 0.7445 - val_precision: 0.6642 - val_recall: 0.9890\n",
            "Epoch 17/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1349 - accuracy: 0.9498 - precision: 0.9599 - recall: 0.9860 - val_loss: 0.7886 - val_accuracy: 0.7205 - val_precision: 0.6435 - val_recall: 0.9890\n",
            "Epoch 18/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1324 - accuracy: 0.9491 - precision: 0.9608 - recall: 0.9842 - val_loss: 0.4582 - val_accuracy: 0.8270 - val_precision: 0.7604 - val_recall: 0.9550\n",
            "Epoch 19/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1285 - accuracy: 0.9487 - precision: 0.9613 - recall: 0.9832 - val_loss: 0.4670 - val_accuracy: 0.8310 - val_precision: 0.7602 - val_recall: 0.9670\n",
            "Epoch 20/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1308 - accuracy: 0.9485 - precision: 0.9627 - recall: 0.9814 - val_loss: 0.9136 - val_accuracy: 0.6925 - val_precision: 0.6202 - val_recall: 0.9930\n",
            "Epoch 21/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1253 - accuracy: 0.9525 - precision: 0.9631 - recall: 0.9856 - val_loss: 1.2480 - val_accuracy: 0.6315 - val_precision: 0.5763 - val_recall: 0.9930\n",
            "Epoch 22/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1228 - accuracy: 0.9509 - precision: 0.9632 - recall: 0.9836 - val_loss: 1.0009 - val_accuracy: 0.6800 - val_precision: 0.6112 - val_recall: 0.9890\n",
            "Epoch 23/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1177 - accuracy: 0.9538 - precision: 0.9655 - recall: 0.9844 - val_loss: 0.5204 - val_accuracy: 0.8220 - val_precision: 0.7500 - val_recall: 0.9660\n",
            "Epoch 24/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1115 - accuracy: 0.9565 - precision: 0.9670 - recall: 0.9858 - val_loss: 0.5300 - val_accuracy: 0.8195 - val_precision: 0.7456 - val_recall: 0.9700\n",
            "Epoch 25/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1145 - accuracy: 0.9549 - precision: 0.9668 - recall: 0.9842 - val_loss: 0.7392 - val_accuracy: 0.7500 - val_precision: 0.6703 - val_recall: 0.9840\n",
            "Epoch 26/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1054 - accuracy: 0.9607 - precision: 0.9712 - recall: 0.9860 - val_loss: 0.6814 - val_accuracy: 0.7920 - val_precision: 0.7122 - val_recall: 0.9800\n",
            "Epoch 27/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0996 - accuracy: 0.9618 - precision: 0.9718 - recall: 0.9866 - val_loss: 0.6041 - val_accuracy: 0.8000 - val_precision: 0.7212 - val_recall: 0.9780\n",
            "Epoch 28/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1014 - accuracy: 0.9605 - precision: 0.9718 - recall: 0.9852 - val_loss: 0.6138 - val_accuracy: 0.8050 - val_precision: 0.7269 - val_recall: 0.9770\n",
            "Epoch 29/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0929 - accuracy: 0.9636 - precision: 0.9721 - recall: 0.9884 - val_loss: 0.8727 - val_accuracy: 0.7335 - val_precision: 0.6554 - val_recall: 0.9850\n",
            "Epoch 30/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.1053 - accuracy: 0.9598 - precision: 0.9716 - recall: 0.9846 - val_loss: 0.6108 - val_accuracy: 0.7975 - val_precision: 0.7196 - val_recall: 0.9750\n",
            "Epoch 31/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0945 - accuracy: 0.9642 - precision: 0.9741 - recall: 0.9868 - val_loss: 0.7703 - val_accuracy: 0.7715 - val_precision: 0.6911 - val_recall: 0.9820\n",
            "Epoch 32/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0920 - accuracy: 0.9643 - precision: 0.9740 - recall: 0.9872 - val_loss: 0.6542 - val_accuracy: 0.7945 - val_precision: 0.7154 - val_recall: 0.9780\n",
            "Epoch 33/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0858 - accuracy: 0.9656 - precision: 0.9757 - recall: 0.9868 - val_loss: 0.5801 - val_accuracy: 0.8235 - val_precision: 0.7494 - val_recall: 0.9720\n",
            "Epoch 34/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0923 - accuracy: 0.9618 - precision: 0.9711 - recall: 0.9874 - val_loss: 0.6144 - val_accuracy: 0.8145 - val_precision: 0.7410 - val_recall: 0.9670\n",
            "Epoch 35/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0861 - accuracy: 0.9647 - precision: 0.9747 - recall: 0.9868 - val_loss: 0.7525 - val_accuracy: 0.7805 - val_precision: 0.7008 - val_recall: 0.9790\n",
            "Epoch 36/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0844 - accuracy: 0.9665 - precision: 0.9757 - recall: 0.9878 - val_loss: 0.7239 - val_accuracy: 0.7905 - val_precision: 0.7104 - val_recall: 0.9810\n",
            "Epoch 37/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0875 - accuracy: 0.9678 - precision: 0.9776 - recall: 0.9872 - val_loss: 0.4921 - val_accuracy: 0.8385 - val_precision: 0.7781 - val_recall: 0.9470\n",
            "Epoch 38/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0834 - accuracy: 0.9669 - precision: 0.9768 - recall: 0.9870 - val_loss: 0.6604 - val_accuracy: 0.8030 - val_precision: 0.7231 - val_recall: 0.9820\n",
            "Epoch 39/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0772 - accuracy: 0.9718 - precision: 0.9796 - recall: 0.9896 - val_loss: 0.5592 - val_accuracy: 0.8345 - val_precision: 0.7674 - val_recall: 0.9600\n",
            "Epoch 40/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0766 - accuracy: 0.9700 - precision: 0.9794 - recall: 0.9878 - val_loss: 0.4470 - val_accuracy: 0.8545 - val_precision: 0.8085 - val_recall: 0.9290\n",
            "Epoch 41/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0692 - accuracy: 0.9736 - precision: 0.9804 - recall: 0.9908 - val_loss: 0.5596 - val_accuracy: 0.8365 - val_precision: 0.7686 - val_recall: 0.9630\n",
            "Epoch 42/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0658 - accuracy: 0.9738 - precision: 0.9810 - recall: 0.9904 - val_loss: 0.7045 - val_accuracy: 0.8150 - val_precision: 0.7383 - val_recall: 0.9760\n",
            "Epoch 43/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0630 - accuracy: 0.9747 - precision: 0.9823 - recall: 0.9900 - val_loss: 0.7949 - val_accuracy: 0.7975 - val_precision: 0.7199 - val_recall: 0.9740\n",
            "Epoch 44/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0767 - accuracy: 0.9703 - precision: 0.9813 - recall: 0.9862 - val_loss: 0.4361 - val_accuracy: 0.8590 - val_precision: 0.8194 - val_recall: 0.9210\n",
            "Epoch 45/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0702 - accuracy: 0.9727 - precision: 0.9823 - recall: 0.9878 - val_loss: 1.3750 - val_accuracy: 0.6965 - val_precision: 0.6235 - val_recall: 0.9920\n",
            "Epoch 46/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0657 - accuracy: 0.9747 - precision: 0.9825 - recall: 0.9898 - val_loss: 1.0396 - val_accuracy: 0.7545 - val_precision: 0.6742 - val_recall: 0.9850\n",
            "Epoch 47/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0572 - accuracy: 0.9796 - precision: 0.9853 - recall: 0.9924 - val_loss: 0.6686 - val_accuracy: 0.8310 - val_precision: 0.7610 - val_recall: 0.9650\n",
            "Epoch 48/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0665 - accuracy: 0.9713 - precision: 0.9800 - recall: 0.9886 - val_loss: 0.6141 - val_accuracy: 0.8390 - val_precision: 0.7747 - val_recall: 0.9560\n",
            "Epoch 49/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0631 - accuracy: 0.9773 - precision: 0.9847 - recall: 0.9904 - val_loss: 0.6571 - val_accuracy: 0.8155 - val_precision: 0.7448 - val_recall: 0.9600\n",
            "Epoch 50/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0591 - accuracy: 0.9767 - precision: 0.9820 - recall: 0.9926 - val_loss: 0.6621 - val_accuracy: 0.8350 - val_precision: 0.7650 - val_recall: 0.9670\n",
            "Epoch 51/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0522 - accuracy: 0.9802 - precision: 0.9857 - recall: 0.9926 - val_loss: 0.7268 - val_accuracy: 0.8205 - val_precision: 0.7486 - val_recall: 0.9650\n",
            "Epoch 52/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0490 - accuracy: 0.9818 - precision: 0.9869 - recall: 0.9932 - val_loss: 0.7053 - val_accuracy: 0.8270 - val_precision: 0.7608 - val_recall: 0.9540\n",
            "Epoch 53/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0521 - accuracy: 0.9796 - precision: 0.9863 - recall: 0.9914 - val_loss: 1.4586 - val_accuracy: 0.7230 - val_precision: 0.6450 - val_recall: 0.9920\n",
            "Epoch 54/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0598 - accuracy: 0.9756 - precision: 0.9837 - recall: 0.9896 - val_loss: 0.8955 - val_accuracy: 0.7855 - val_precision: 0.7076 - val_recall: 0.9730\n",
            "Epoch 55/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0461 - accuracy: 0.9807 - precision: 0.9873 - recall: 0.9916 - val_loss: 0.6849 - val_accuracy: 0.8375 - val_precision: 0.7685 - val_recall: 0.9660\n",
            "Epoch 56/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0552 - accuracy: 0.9804 - precision: 0.9876 - recall: 0.9908 - val_loss: 0.7066 - val_accuracy: 0.8280 - val_precision: 0.7559 - val_recall: 0.9690\n",
            "Epoch 57/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0481 - accuracy: 0.9811 - precision: 0.9867 - recall: 0.9926 - val_loss: 0.7494 - val_accuracy: 0.8200 - val_precision: 0.7500 - val_recall: 0.9600\n",
            "Epoch 58/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0436 - accuracy: 0.9827 - precision: 0.9888 - recall: 0.9922 - val_loss: 1.0603 - val_accuracy: 0.7860 - val_precision: 0.7061 - val_recall: 0.9800\n",
            "Epoch 59/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0429 - accuracy: 0.9845 - precision: 0.9904 - recall: 0.9926 - val_loss: 0.8651 - val_accuracy: 0.8090 - val_precision: 0.7348 - val_recall: 0.9670\n",
            "Epoch 60/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0587 - accuracy: 0.9784 - precision: 0.9853 - recall: 0.9910 - val_loss: 0.7858 - val_accuracy: 0.8210 - val_precision: 0.7485 - val_recall: 0.9670\n",
            "Epoch 61/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0390 - accuracy: 0.9845 - precision: 0.9898 - recall: 0.9932 - val_loss: 0.7811 - val_accuracy: 0.8360 - val_precision: 0.7662 - val_recall: 0.9670\n",
            "Epoch 62/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0349 - accuracy: 0.9885 - precision: 0.9920 - recall: 0.9954 - val_loss: 0.6776 - val_accuracy: 0.8405 - val_precision: 0.7807 - val_recall: 0.9470\n",
            "Epoch 63/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0501 - accuracy: 0.9825 - precision: 0.9886 - recall: 0.9922 - val_loss: 0.9426 - val_accuracy: 0.8080 - val_precision: 0.7312 - val_recall: 0.9740\n",
            "Epoch 64/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0325 - accuracy: 0.9891 - precision: 0.9924 - recall: 0.9956 - val_loss: 0.6163 - val_accuracy: 0.8480 - val_precision: 0.8058 - val_recall: 0.9170\n",
            "Epoch 65/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0337 - accuracy: 0.9880 - precision: 0.9928 - recall: 0.9940 - val_loss: 0.9211 - val_accuracy: 0.8160 - val_precision: 0.7394 - val_recall: 0.9760\n",
            "Epoch 66/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0323 - accuracy: 0.9889 - precision: 0.9922 - recall: 0.9956 - val_loss: 0.9798 - val_accuracy: 0.8150 - val_precision: 0.7390 - val_recall: 0.9740\n",
            "Epoch 67/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0569 - accuracy: 0.9778 - precision: 0.9861 - recall: 0.9896 - val_loss: 0.7293 - val_accuracy: 0.8290 - val_precision: 0.7599 - val_recall: 0.9620\n",
            "Epoch 68/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0369 - accuracy: 0.9862 - precision: 0.9902 - recall: 0.9946 - val_loss: 0.6962 - val_accuracy: 0.8525 - val_precision: 0.7945 - val_recall: 0.9510\n",
            "Epoch 69/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0410 - accuracy: 0.9829 - precision: 0.9894 - recall: 0.9918 - val_loss: 0.8432 - val_accuracy: 0.8240 - val_precision: 0.7516 - val_recall: 0.9680\n",
            "Epoch 70/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0314 - accuracy: 0.9893 - precision: 0.9930 - recall: 0.9952 - val_loss: 1.1263 - val_accuracy: 0.7850 - val_precision: 0.7080 - val_recall: 0.9700\n",
            "Epoch 71/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0426 - accuracy: 0.9858 - precision: 0.9914 - recall: 0.9930 - val_loss: 1.0698 - val_accuracy: 0.7970 - val_precision: 0.7174 - val_recall: 0.9800\n",
            "Epoch 72/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0296 - accuracy: 0.9896 - precision: 0.9930 - recall: 0.9956 - val_loss: 1.1002 - val_accuracy: 0.8050 - val_precision: 0.7276 - val_recall: 0.9750\n",
            "Epoch 73/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0302 - accuracy: 0.9902 - precision: 0.9946 - recall: 0.9946 - val_loss: 1.1458 - val_accuracy: 0.7915 - val_precision: 0.7132 - val_recall: 0.9750\n",
            "Epoch 74/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0246 - accuracy: 0.9916 - precision: 0.9948 - recall: 0.9960 - val_loss: 0.9691 - val_accuracy: 0.8100 - val_precision: 0.7352 - val_recall: 0.9690\n",
            "Epoch 75/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0356 - accuracy: 0.9882 - precision: 0.9924 - recall: 0.9946 - val_loss: 0.8544 - val_accuracy: 0.8365 - val_precision: 0.7690 - val_recall: 0.9620\n",
            "Epoch 76/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0236 - accuracy: 0.9904 - precision: 0.9942 - recall: 0.9952 - val_loss: 1.0821 - val_accuracy: 0.8165 - val_precision: 0.7403 - val_recall: 0.9750\n",
            "Epoch 77/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0320 - accuracy: 0.9865 - precision: 0.9926 - recall: 0.9926 - val_loss: 0.9611 - val_accuracy: 0.8245 - val_precision: 0.7521 - val_recall: 0.9680\n",
            "Epoch 78/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0282 - accuracy: 0.9896 - precision: 0.9938 - recall: 0.9948 - val_loss: 1.0211 - val_accuracy: 0.8195 - val_precision: 0.7452 - val_recall: 0.9710\n",
            "Epoch 79/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0220 - accuracy: 0.9916 - precision: 0.9942 - recall: 0.9966 - val_loss: 0.9357 - val_accuracy: 0.8415 - val_precision: 0.7721 - val_recall: 0.9690\n",
            "Epoch 80/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0290 - accuracy: 0.9902 - precision: 0.9938 - recall: 0.9954 - val_loss: 0.8678 - val_accuracy: 0.8405 - val_precision: 0.7780 - val_recall: 0.9530\n",
            "Epoch 81/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0344 - accuracy: 0.9878 - precision: 0.9918 - recall: 0.9948 - val_loss: 1.1414 - val_accuracy: 0.8040 - val_precision: 0.7282 - val_recall: 0.9700\n",
            "Epoch 82/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0294 - accuracy: 0.9885 - precision: 0.9934 - recall: 0.9940 - val_loss: 1.2082 - val_accuracy: 0.7960 - val_precision: 0.7183 - val_recall: 0.9740\n",
            "Epoch 83/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0397 - accuracy: 0.9856 - precision: 0.9910 - recall: 0.9932 - val_loss: 1.0273 - val_accuracy: 0.8335 - val_precision: 0.7632 - val_recall: 0.9670\n",
            "Epoch 84/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0199 - accuracy: 0.9938 - precision: 0.9960 - recall: 0.9972 - val_loss: 1.2479 - val_accuracy: 0.8070 - val_precision: 0.7291 - val_recall: 0.9770\n",
            "Epoch 85/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0161 - accuracy: 0.9945 - precision: 0.9970 - recall: 0.9970 - val_loss: 1.2002 - val_accuracy: 0.8060 - val_precision: 0.7315 - val_recall: 0.9670\n",
            "Epoch 86/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0267 - accuracy: 0.9896 - precision: 0.9932 - recall: 0.9954 - val_loss: 1.0205 - val_accuracy: 0.8265 - val_precision: 0.7565 - val_recall: 0.9630\n",
            "Epoch 87/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0348 - accuracy: 0.9865 - precision: 0.9916 - recall: 0.9936 - val_loss: 0.6333 - val_accuracy: 0.8490 - val_precision: 0.8415 - val_recall: 0.8600\n",
            "Epoch 88/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0329 - accuracy: 0.9887 - precision: 0.9930 - recall: 0.9946 - val_loss: 1.4825 - val_accuracy: 0.7805 - val_precision: 0.6996 - val_recall: 0.9830\n",
            "Epoch 89/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0225 - accuracy: 0.9920 - precision: 0.9952 - recall: 0.9960 - val_loss: 0.8364 - val_accuracy: 0.8440 - val_precision: 0.8050 - val_recall: 0.9080\n",
            "Epoch 90/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0266 - accuracy: 0.9896 - precision: 0.9938 - recall: 0.9948 - val_loss: 1.2953 - val_accuracy: 0.8005 - val_precision: 0.7221 - val_recall: 0.9770\n",
            "Epoch 91/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0200 - accuracy: 0.9925 - precision: 0.9948 - recall: 0.9970 - val_loss: 1.0782 - val_accuracy: 0.8185 - val_precision: 0.7452 - val_recall: 0.9680\n",
            "Epoch 92/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0147 - accuracy: 0.9949 - precision: 0.9964 - recall: 0.9980 - val_loss: 1.2667 - val_accuracy: 0.8065 - val_precision: 0.7306 - val_recall: 0.9710\n",
            "Epoch 93/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0105 - accuracy: 0.9975 - precision: 0.9990 - recall: 0.9982 - val_loss: 1.1699 - val_accuracy: 0.8245 - val_precision: 0.7533 - val_recall: 0.9650\n",
            "Epoch 94/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0332 - accuracy: 0.9873 - precision: 0.9918 - recall: 0.9942 - val_loss: 1.5412 - val_accuracy: 0.7820 - val_precision: 0.7029 - val_recall: 0.9770\n",
            "Epoch 95/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0226 - accuracy: 0.9922 - precision: 0.9954 - recall: 0.9960 - val_loss: 1.0015 - val_accuracy: 0.8365 - val_precision: 0.7738 - val_recall: 0.9510\n",
            "Epoch 96/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0655 - accuracy: 0.9785 - precision: 0.9882 - recall: 0.9882 - val_loss: 1.2685 - val_accuracy: 0.7925 - val_precision: 0.7159 - val_recall: 0.9700\n",
            "Epoch 97/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0440 - accuracy: 0.9838 - precision: 0.9904 - recall: 0.9918 - val_loss: 0.8089 - val_accuracy: 0.8510 - val_precision: 0.7995 - val_recall: 0.9370\n",
            "Epoch 98/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0275 - accuracy: 0.9904 - precision: 0.9942 - recall: 0.9952 - val_loss: 1.9624 - val_accuracy: 0.7445 - val_precision: 0.6642 - val_recall: 0.9890\n",
            "Epoch 99/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0162 - accuracy: 0.9944 - precision: 0.9960 - recall: 0.9978 - val_loss: 0.9219 - val_accuracy: 0.8440 - val_precision: 0.7871 - val_recall: 0.9430\n",
            "Epoch 100/100\n",
            "172/172 [==============================] - 1s 6ms/step - loss: 0.0158 - accuracy: 0.9953 - precision: 0.9974 - recall: 0.9974 - val_loss: 1.3793 - val_accuracy: 0.7950 - val_precision: 0.7172 - val_recall: 0.9740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NupMM3EzzPWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "47cb3e15-63d9-4792-bfcf-7394bb18935f"
      },
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(121)\n",
        "plt.scatter(history.history['precision'], history.history['recall'])\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.scatter(history.history['val_precision'], history.history['val_recall'])\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAExCAYAAADBbf6RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M46OobHJ0SoT",
        "colab_type": "text"
      },
      "source": [
        "### BorderlineSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l94rfFAo0VAI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "473ba62b-4e86-4fea-91c9-e8cecac50165"
      },
      "source": [
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1] * x_train.shape[2] * x_train.shape[3])).astype(np.float32)\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1] * x_test.shape[2] * x_test.shape[3])).astype(np.float32)\n",
        "\n",
        "smote = BorderlineSMOTE()\n",
        "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(2048)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32).prefetch(2048)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmUKgop70sn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MyModel()\n",
        "loss_object = 'binary_crossentropy'\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "metrics = ['accuracy',\n",
        "           tf.keras.metrics.Precision(name='precision'),\n",
        "           tf.keras.metrics.Recall(name='recall')]\n",
        "model.compile(optimizer=optimizer, loss=loss_object, metrics=metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQHATnNp1K_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98dc9a99-a9bf-4cf4-beca-c67ec0470ffa"
      },
      "source": [
        "history = model.fit(train_ds,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=test_ds)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 313 steps, validate for 63 steps\n",
            "Epoch 1/100\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6332 - accuracy: 0.7343 - precision: 0.7495 - recall: 0.7038 - val_loss: 0.4618 - val_accuracy: 0.7875 - val_precision: 0.7762 - val_recall: 0.8080\n",
            "Epoch 2/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.3744 - accuracy: 0.8446 - precision: 0.8782 - recall: 0.8002 - val_loss: 0.4066 - val_accuracy: 0.8230 - val_precision: 0.8094 - val_recall: 0.8450\n",
            "Epoch 3/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.3185 - accuracy: 0.8722 - precision: 0.8985 - recall: 0.8392 - val_loss: 0.9271 - val_accuracy: 0.6415 - val_precision: 0.5853 - val_recall: 0.9710\n",
            "Epoch 4/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2524 - accuracy: 0.9048 - precision: 0.9343 - recall: 0.8708 - val_loss: 0.5595 - val_accuracy: 0.7875 - val_precision: 0.7203 - val_recall: 0.9400\n",
            "Epoch 5/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2010 - accuracy: 0.9314 - precision: 0.9582 - recall: 0.9022 - val_loss: 0.4373 - val_accuracy: 0.8315 - val_precision: 0.8478 - val_recall: 0.8080\n",
            "Epoch 6/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1833 - accuracy: 0.9387 - precision: 0.9594 - recall: 0.9162 - val_loss: 0.4309 - val_accuracy: 0.8350 - val_precision: 0.8215 - val_recall: 0.8560\n",
            "Epoch 7/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1861 - accuracy: 0.9379 - precision: 0.9570 - recall: 0.9170 - val_loss: 0.7494 - val_accuracy: 0.7605 - val_precision: 0.6857 - val_recall: 0.9620\n",
            "Epoch 8/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1454 - accuracy: 0.9554 - precision: 0.9703 - recall: 0.9396 - val_loss: 0.4841 - val_accuracy: 0.8205 - val_precision: 0.7890 - val_recall: 0.8750\n",
            "Epoch 9/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1303 - accuracy: 0.9608 - precision: 0.9766 - recall: 0.9442 - val_loss: 0.4740 - val_accuracy: 0.8370 - val_precision: 0.8075 - val_recall: 0.8850\n",
            "Epoch 10/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1265 - accuracy: 0.9614 - precision: 0.9743 - recall: 0.9478 - val_loss: 0.6292 - val_accuracy: 0.8080 - val_precision: 0.7433 - val_recall: 0.9410\n",
            "Epoch 11/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1225 - accuracy: 0.9640 - precision: 0.9776 - recall: 0.9498 - val_loss: 0.7388 - val_accuracy: 0.7835 - val_precision: 0.7108 - val_recall: 0.9560\n",
            "Epoch 12/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1171 - accuracy: 0.9642 - precision: 0.9737 - recall: 0.9542 - val_loss: 0.6527 - val_accuracy: 0.8130 - val_precision: 0.7465 - val_recall: 0.9480\n",
            "Epoch 13/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1048 - accuracy: 0.9688 - precision: 0.9790 - recall: 0.9582 - val_loss: 0.7147 - val_accuracy: 0.8180 - val_precision: 0.7465 - val_recall: 0.9630\n",
            "Epoch 14/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0973 - accuracy: 0.9709 - precision: 0.9810 - recall: 0.9604 - val_loss: 0.6139 - val_accuracy: 0.8270 - val_precision: 0.7725 - val_recall: 0.9270\n",
            "Epoch 15/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0999 - accuracy: 0.9691 - precision: 0.9801 - recall: 0.9576 - val_loss: 0.5900 - val_accuracy: 0.8365 - val_precision: 0.7830 - val_recall: 0.9310\n",
            "Epoch 16/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0946 - accuracy: 0.9711 - precision: 0.9814 - recall: 0.9604 - val_loss: 0.8257 - val_accuracy: 0.7925 - val_precision: 0.7194 - val_recall: 0.9590\n",
            "Epoch 17/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0881 - accuracy: 0.9746 - precision: 0.9841 - recall: 0.9648 - val_loss: 1.3541 - val_accuracy: 0.7080 - val_precision: 0.6337 - val_recall: 0.9860\n",
            "Epoch 18/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0859 - accuracy: 0.9724 - precision: 0.9801 - recall: 0.9644 - val_loss: 0.5840 - val_accuracy: 0.8405 - val_precision: 0.7958 - val_recall: 0.9160\n",
            "Epoch 19/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0725 - accuracy: 0.9779 - precision: 0.9854 - recall: 0.9702 - val_loss: 1.0341 - val_accuracy: 0.7690 - val_precision: 0.6908 - val_recall: 0.9740\n",
            "Epoch 20/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0656 - accuracy: 0.9814 - precision: 0.9878 - recall: 0.9748 - val_loss: 0.6863 - val_accuracy: 0.8340 - val_precision: 0.7685 - val_recall: 0.9560\n",
            "Epoch 21/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0652 - accuracy: 0.9801 - precision: 0.9862 - recall: 0.9738 - val_loss: 0.7345 - val_accuracy: 0.8255 - val_precision: 0.7619 - val_recall: 0.9470\n",
            "Epoch 22/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0703 - accuracy: 0.9785 - precision: 0.9840 - recall: 0.9728 - val_loss: 0.6731 - val_accuracy: 0.8350 - val_precision: 0.7755 - val_recall: 0.9430\n",
            "Epoch 23/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0758 - accuracy: 0.9750 - precision: 0.9814 - recall: 0.9684 - val_loss: 0.8202 - val_accuracy: 0.8215 - val_precision: 0.7506 - val_recall: 0.9630\n",
            "Epoch 24/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0532 - accuracy: 0.9840 - precision: 0.9887 - recall: 0.9792 - val_loss: 1.1452 - val_accuracy: 0.7720 - val_precision: 0.6937 - val_recall: 0.9740\n",
            "Epoch 25/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0604 - accuracy: 0.9796 - precision: 0.9850 - recall: 0.9740 - val_loss: 0.6858 - val_accuracy: 0.8375 - val_precision: 0.7829 - val_recall: 0.9340\n",
            "Epoch 26/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0450 - accuracy: 0.9867 - precision: 0.9891 - recall: 0.9842 - val_loss: 0.7826 - val_accuracy: 0.8360 - val_precision: 0.7732 - val_recall: 0.9510\n",
            "Epoch 27/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0465 - accuracy: 0.9845 - precision: 0.9881 - recall: 0.9808 - val_loss: 0.6570 - val_accuracy: 0.8480 - val_precision: 0.8053 - val_recall: 0.9180\n",
            "Epoch 28/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0431 - accuracy: 0.9872 - precision: 0.9905 - recall: 0.9838 - val_loss: 0.6964 - val_accuracy: 0.8425 - val_precision: 0.7945 - val_recall: 0.9240\n",
            "Epoch 29/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0432 - accuracy: 0.9858 - precision: 0.9899 - recall: 0.9816 - val_loss: 0.7875 - val_accuracy: 0.8405 - val_precision: 0.7802 - val_recall: 0.9480\n",
            "Epoch 30/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0563 - accuracy: 0.9802 - precision: 0.9858 - recall: 0.9744 - val_loss: 1.0845 - val_accuracy: 0.7885 - val_precision: 0.7110 - val_recall: 0.9720\n",
            "Epoch 31/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0448 - accuracy: 0.9859 - precision: 0.9899 - recall: 0.9818 - val_loss: 0.7986 - val_accuracy: 0.8380 - val_precision: 0.7735 - val_recall: 0.9560\n",
            "Epoch 32/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0316 - accuracy: 0.9906 - precision: 0.9942 - recall: 0.9870 - val_loss: 1.1748 - val_accuracy: 0.8095 - val_precision: 0.7318 - val_recall: 0.9770\n",
            "Epoch 33/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0352 - accuracy: 0.9895 - precision: 0.9920 - recall: 0.9870 - val_loss: 1.0986 - val_accuracy: 0.8065 - val_precision: 0.7324 - val_recall: 0.9660\n",
            "Epoch 34/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0381 - accuracy: 0.9888 - precision: 0.9914 - recall: 0.9862 - val_loss: 0.8607 - val_accuracy: 0.8395 - val_precision: 0.7758 - val_recall: 0.9550\n",
            "Epoch 35/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0312 - accuracy: 0.9902 - precision: 0.9928 - recall: 0.9876 - val_loss: 0.8050 - val_accuracy: 0.8425 - val_precision: 0.7842 - val_recall: 0.9450\n",
            "Epoch 36/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0363 - accuracy: 0.9882 - precision: 0.9915 - recall: 0.9848 - val_loss: 0.7478 - val_accuracy: 0.8410 - val_precision: 0.8007 - val_recall: 0.9080\n",
            "Epoch 37/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0297 - accuracy: 0.9904 - precision: 0.9924 - recall: 0.9884 - val_loss: 1.0518 - val_accuracy: 0.8235 - val_precision: 0.7521 - val_recall: 0.9650\n",
            "Epoch 38/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0310 - accuracy: 0.9895 - precision: 0.9922 - recall: 0.9868 - val_loss: 1.0702 - val_accuracy: 0.8235 - val_precision: 0.7533 - val_recall: 0.9620\n",
            "Epoch 39/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0256 - accuracy: 0.9909 - precision: 0.9926 - recall: 0.9892 - val_loss: 1.1914 - val_accuracy: 0.8100 - val_precision: 0.7356 - val_recall: 0.9680\n",
            "Epoch 40/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0230 - accuracy: 0.9926 - precision: 0.9946 - recall: 0.9906 - val_loss: 1.1356 - val_accuracy: 0.8205 - val_precision: 0.7506 - val_recall: 0.9600\n",
            "Epoch 41/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0312 - accuracy: 0.9907 - precision: 0.9932 - recall: 0.9882 - val_loss: 1.7331 - val_accuracy: 0.7470 - val_precision: 0.6671 - val_recall: 0.9860\n",
            "Epoch 42/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0311 - accuracy: 0.9897 - precision: 0.9918 - recall: 0.9876 - val_loss: 0.9779 - val_accuracy: 0.8345 - val_precision: 0.7767 - val_recall: 0.9390\n",
            "Epoch 43/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0327 - accuracy: 0.9901 - precision: 0.9924 - recall: 0.9878 - val_loss: 1.1443 - val_accuracy: 0.8085 - val_precision: 0.7390 - val_recall: 0.9540\n",
            "Epoch 44/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0269 - accuracy: 0.9918 - precision: 0.9940 - recall: 0.9896 - val_loss: 1.0626 - val_accuracy: 0.8295 - val_precision: 0.7634 - val_recall: 0.9550\n",
            "Epoch 45/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0201 - accuracy: 0.9931 - precision: 0.9948 - recall: 0.9914 - val_loss: 1.0772 - val_accuracy: 0.8235 - val_precision: 0.7561 - val_recall: 0.9550\n",
            "Epoch 46/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0304 - accuracy: 0.9886 - precision: 0.9912 - recall: 0.9860 - val_loss: 1.2921 - val_accuracy: 0.8230 - val_precision: 0.7496 - val_recall: 0.9700\n",
            "Epoch 47/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0311 - accuracy: 0.9886 - precision: 0.9898 - recall: 0.9874 - val_loss: 1.1383 - val_accuracy: 0.8290 - val_precision: 0.7591 - val_recall: 0.9640\n",
            "Epoch 48/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0225 - accuracy: 0.9933 - precision: 0.9954 - recall: 0.9912 - val_loss: 1.2452 - val_accuracy: 0.8080 - val_precision: 0.7384 - val_recall: 0.9540\n",
            "Epoch 49/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0180 - accuracy: 0.9944 - precision: 0.9948 - recall: 0.9940 - val_loss: 1.1422 - val_accuracy: 0.8170 - val_precision: 0.7484 - val_recall: 0.9550\n",
            "Epoch 50/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0215 - accuracy: 0.9932 - precision: 0.9954 - recall: 0.9910 - val_loss: 1.0295 - val_accuracy: 0.8375 - val_precision: 0.7810 - val_recall: 0.9380\n",
            "Epoch 51/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0214 - accuracy: 0.9928 - precision: 0.9936 - recall: 0.9920 - val_loss: 0.9151 - val_accuracy: 0.8500 - val_precision: 0.8086 - val_recall: 0.9170\n",
            "Epoch 52/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0206 - accuracy: 0.9930 - precision: 0.9950 - recall: 0.9910 - val_loss: 1.5009 - val_accuracy: 0.8065 - val_precision: 0.7296 - val_recall: 0.9740\n",
            "Epoch 53/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0276 - accuracy: 0.9911 - precision: 0.9918 - recall: 0.9904 - val_loss: 1.2526 - val_accuracy: 0.8320 - val_precision: 0.7610 - val_recall: 0.9680\n",
            "Epoch 54/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0179 - accuracy: 0.9943 - precision: 0.9954 - recall: 0.9932 - val_loss: 0.9885 - val_accuracy: 0.8450 - val_precision: 0.7880 - val_recall: 0.9440\n",
            "Epoch 55/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0306 - accuracy: 0.9896 - precision: 0.9922 - recall: 0.9870 - val_loss: 1.4811 - val_accuracy: 0.8030 - val_precision: 0.7278 - val_recall: 0.9680\n",
            "Epoch 56/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0210 - accuracy: 0.9935 - precision: 0.9948 - recall: 0.9922 - val_loss: 1.5786 - val_accuracy: 0.8075 - val_precision: 0.7293 - val_recall: 0.9780\n",
            "Epoch 57/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0146 - accuracy: 0.9954 - precision: 0.9972 - recall: 0.9936 - val_loss: 1.4944 - val_accuracy: 0.8090 - val_precision: 0.7334 - val_recall: 0.9710\n",
            "Epoch 58/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0159 - accuracy: 0.9946 - precision: 0.9956 - recall: 0.9936 - val_loss: 1.0877 - val_accuracy: 0.8430 - val_precision: 0.7816 - val_recall: 0.9520\n",
            "Epoch 59/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0430 - accuracy: 0.9848 - precision: 0.9871 - recall: 0.9824 - val_loss: 0.9852 - val_accuracy: 0.8450 - val_precision: 0.7939 - val_recall: 0.9320\n",
            "Epoch 60/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0253 - accuracy: 0.9918 - precision: 0.9936 - recall: 0.9900 - val_loss: 1.6413 - val_accuracy: 0.7930 - val_precision: 0.7161 - val_recall: 0.9710\n",
            "Epoch 61/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0093 - accuracy: 0.9971 - precision: 0.9984 - recall: 0.9958 - val_loss: 1.6252 - val_accuracy: 0.8130 - val_precision: 0.7378 - val_recall: 0.9710\n",
            "Epoch 62/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0148 - accuracy: 0.9949 - precision: 0.9956 - recall: 0.9942 - val_loss: 1.8037 - val_accuracy: 0.7885 - val_precision: 0.7095 - val_recall: 0.9770\n",
            "Epoch 63/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0150 - accuracy: 0.9941 - precision: 0.9946 - recall: 0.9936 - val_loss: 0.9443 - val_accuracy: 0.8500 - val_precision: 0.8235 - val_recall: 0.8910\n",
            "Epoch 64/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0135 - accuracy: 0.9958 - precision: 0.9962 - recall: 0.9954 - val_loss: 1.6131 - val_accuracy: 0.8035 - val_precision: 0.7270 - val_recall: 0.9720\n",
            "Epoch 65/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0144 - accuracy: 0.9961 - precision: 0.9968 - recall: 0.9954 - val_loss: 2.2216 - val_accuracy: 0.7635 - val_precision: 0.6839 - val_recall: 0.9800\n",
            "Epoch 66/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0187 - accuracy: 0.9949 - precision: 0.9960 - recall: 0.9938 - val_loss: 1.4865 - val_accuracy: 0.8135 - val_precision: 0.7399 - val_recall: 0.9670\n",
            "Epoch 67/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0177 - accuracy: 0.9940 - precision: 0.9954 - recall: 0.9926 - val_loss: 1.0655 - val_accuracy: 0.8500 - val_precision: 0.7956 - val_recall: 0.9420\n",
            "Epoch 68/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0465 - accuracy: 0.9857 - precision: 0.9883 - recall: 0.9830 - val_loss: 1.6358 - val_accuracy: 0.8060 - val_precision: 0.7294 - val_recall: 0.9730\n",
            "Epoch 69/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0086 - accuracy: 0.9971 - precision: 0.9976 - recall: 0.9966 - val_loss: 1.5008 - val_accuracy: 0.8235 - val_precision: 0.7518 - val_recall: 0.9660\n",
            "Epoch 70/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0083 - accuracy: 0.9979 - precision: 0.9984 - recall: 0.9974 - val_loss: 1.1569 - val_accuracy: 0.8455 - val_precision: 0.7858 - val_recall: 0.9500\n",
            "Epoch 71/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0061 - accuracy: 0.9981 - precision: 0.9986 - recall: 0.9976 - val_loss: 1.2553 - val_accuracy: 0.8380 - val_precision: 0.7757 - val_recall: 0.9510\n",
            "Epoch 72/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0274 - accuracy: 0.9903 - precision: 0.9920 - recall: 0.9886 - val_loss: 1.2921 - val_accuracy: 0.8250 - val_precision: 0.7608 - val_recall: 0.9480\n",
            "Epoch 73/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0106 - accuracy: 0.9967 - precision: 0.9976 - recall: 0.9958 - val_loss: 1.4164 - val_accuracy: 0.8285 - val_precision: 0.7589 - val_recall: 0.9630\n",
            "Epoch 74/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0142 - accuracy: 0.9955 - precision: 0.9958 - recall: 0.9952 - val_loss: 1.5942 - val_accuracy: 0.8135 - val_precision: 0.7395 - val_recall: 0.9680\n",
            "Epoch 75/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0196 - accuracy: 0.9930 - precision: 0.9938 - recall: 0.9922 - val_loss: 1.0565 - val_accuracy: 0.8430 - val_precision: 0.8085 - val_recall: 0.8990\n",
            "Epoch 76/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0114 - accuracy: 0.9963 - precision: 0.9976 - recall: 0.9950 - val_loss: 1.6551 - val_accuracy: 0.8170 - val_precision: 0.7438 - val_recall: 0.9670\n",
            "Epoch 77/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0050 - accuracy: 0.9985 - precision: 0.9986 - recall: 0.9984 - val_loss: 1.8474 - val_accuracy: 0.8095 - val_precision: 0.7318 - val_recall: 0.9770\n",
            "Epoch 78/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.9984 - precision: 0.9994 - recall: 0.9974 - val_loss: 1.5160 - val_accuracy: 0.8235 - val_precision: 0.7518 - val_recall: 0.9660\n",
            "Epoch 79/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0031 - accuracy: 0.9995 - precision: 0.9996 - recall: 0.9994 - val_loss: 2.2857 - val_accuracy: 0.7795 - val_precision: 0.6984 - val_recall: 0.9840\n",
            "Epoch 80/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0178 - accuracy: 0.9941 - precision: 0.9956 - recall: 0.9926 - val_loss: 1.2975 - val_accuracy: 0.8425 - val_precision: 0.7805 - val_recall: 0.9530\n",
            "Epoch 81/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0199 - accuracy: 0.9938 - precision: 0.9948 - recall: 0.9928 - val_loss: 1.8831 - val_accuracy: 0.8125 - val_precision: 0.7355 - val_recall: 0.9760\n",
            "Epoch 82/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0066 - accuracy: 0.9980 - precision: 0.9982 - recall: 0.9978 - val_loss: 1.7390 - val_accuracy: 0.8185 - val_precision: 0.7437 - val_recall: 0.9720\n",
            "Epoch 83/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0036 - accuracy: 0.9991 - precision: 0.9996 - recall: 0.9986 - val_loss: 1.5980 - val_accuracy: 0.8250 - val_precision: 0.7555 - val_recall: 0.9610\n",
            "Epoch 84/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0380 - accuracy: 0.9876 - precision: 0.9903 - recall: 0.9848 - val_loss: 1.0826 - val_accuracy: 0.8380 - val_precision: 0.7996 - val_recall: 0.9020\n",
            "Epoch 85/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0191 - accuracy: 0.9939 - precision: 0.9946 - recall: 0.9932 - val_loss: 1.1337 - val_accuracy: 0.8430 - val_precision: 0.7942 - val_recall: 0.9260\n",
            "Epoch 86/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0128 - accuracy: 0.9959 - precision: 0.9968 - recall: 0.9950 - val_loss: 2.4393 - val_accuracy: 0.7795 - val_precision: 0.6978 - val_recall: 0.9860\n",
            "Epoch 87/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0651 - accuracy: 0.9780 - precision: 0.9809 - recall: 0.9750 - val_loss: 1.5663 - val_accuracy: 0.8065 - val_precision: 0.7317 - val_recall: 0.9680\n",
            "Epoch 88/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0173 - accuracy: 0.9945 - precision: 0.9960 - recall: 0.9930 - val_loss: 1.6892 - val_accuracy: 0.8075 - val_precision: 0.7335 - val_recall: 0.9660\n",
            "Epoch 89/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0087 - accuracy: 0.9975 - precision: 0.9988 - recall: 0.9962 - val_loss: 2.0869 - val_accuracy: 0.7945 - val_precision: 0.7148 - val_recall: 0.9800\n",
            "Epoch 90/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0033 - accuracy: 0.9990 - precision: 0.9994 - recall: 0.9986 - val_loss: 1.5661 - val_accuracy: 0.8280 - val_precision: 0.7579 - val_recall: 0.9640\n",
            "Epoch 91/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0031 - accuracy: 0.9995 - precision: 0.9998 - recall: 0.9992 - val_loss: 1.7644 - val_accuracy: 0.8135 - val_precision: 0.7373 - val_recall: 0.9740\n",
            "Epoch 92/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0089 - accuracy: 0.9971 - precision: 0.9976 - recall: 0.9966 - val_loss: 1.5453 - val_accuracy: 0.8125 - val_precision: 0.7440 - val_recall: 0.9530\n",
            "Epoch 93/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0167 - accuracy: 0.9941 - precision: 0.9952 - recall: 0.9930 - val_loss: 1.9576 - val_accuracy: 0.7900 - val_precision: 0.7123 - val_recall: 0.9730\n",
            "Epoch 94/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0114 - accuracy: 0.9968 - precision: 0.9972 - recall: 0.9964 - val_loss: 1.7145 - val_accuracy: 0.8165 - val_precision: 0.7436 - val_recall: 0.9660\n",
            "Epoch 95/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0150 - accuracy: 0.9949 - precision: 0.9954 - recall: 0.9944 - val_loss: 1.7745 - val_accuracy: 0.8170 - val_precision: 0.7424 - val_recall: 0.9710\n",
            "Epoch 96/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0040 - accuracy: 0.9989 - precision: 0.9990 - recall: 0.9988 - val_loss: 2.2451 - val_accuracy: 0.7855 - val_precision: 0.7052 - val_recall: 0.9810\n",
            "Epoch 97/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0107 - accuracy: 0.9963 - precision: 0.9972 - recall: 0.9954 - val_loss: 1.4612 - val_accuracy: 0.8260 - val_precision: 0.7604 - val_recall: 0.9520\n",
            "Epoch 98/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0077 - accuracy: 0.9976 - precision: 0.9978 - recall: 0.9974 - val_loss: 1.9382 - val_accuracy: 0.7975 - val_precision: 0.7218 - val_recall: 0.9680\n",
            "Epoch 99/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0351 - accuracy: 0.9891 - precision: 0.9920 - recall: 0.9862 - val_loss: 2.5664 - val_accuracy: 0.7545 - val_precision: 0.6747 - val_recall: 0.9830\n",
            "Epoch 100/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0145 - accuracy: 0.9952 - precision: 0.9960 - recall: 0.9944 - val_loss: 0.9332 - val_accuracy: 0.8500 - val_precision: 0.8211 - val_recall: 0.8950\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
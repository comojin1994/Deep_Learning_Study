{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Global_Wheat_Detection_Pseudo_Labeling.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNAKxfZNT0AbFwiA/co3a8q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comojin1994/Deep_Learning_Study/blob/master/Kaggle/Global_Wheat_Detection/Global_Wheat_Detection_Pseudo_Labeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzdZ3aE4qkZ_",
        "colab_type": "text"
      },
      "source": [
        "# Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6g4qhuqqWdm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "10d3d22a-df8d-4901-9452-f6fdb677f707"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5TM2AZQqQV8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3fc108a4-b4e4-4ea1-8f52-1573ab31901d"
      },
      "source": [
        "%cd ./drive/My\\ Drive/Kaggle/Global_Wheat_Detection/input/global-wheat-detection/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Kaggle/Global_Wheat_Detection/input/global-wheat-detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE0caXtN65jz",
        "colab_type": "code",
        "outputId": "fdf3dc1a-5923-4bea-e356-80e47dd06959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Kaggle/Global_Wheat_Detection/input\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRDP7Jz08PoJ",
        "colab_type": "code",
        "outputId": "258e42ec-72be-4775-fddf-8811a8cd2d12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Kaggle/Global_Wheat_Detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxE9O7u567td",
        "colab_type": "code",
        "outputId": "cf1cfd00-b031-4aea-bc43-3af584f099e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd output/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Kaggle/Global_Wheat_Detection/output\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5rlJ0YxyQsv",
        "colab_type": "code",
        "outputId": "f5b60639-e9ea-477b-900d-b1dfa81cbad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data_Augmentation_Tutorial.ipynb\n",
            "Global_Wheat_Detection_FasterRCNN_resnet50fpn.ipynb\n",
            "Global_Wheat_Detection_FasterRCNN_resnet50_Inference.ipynb\n",
            "Global_Wheat_Detection_FasterRCNN_ResNext101.ipynb\n",
            "Global_Wheat_Detection_Pseudo_Labeling.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1gMikZcqo8l",
        "colab_type": "text"
      },
      "source": [
        "# Load Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTF0R58hqrA3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d50d6216-fef2-4598-91c6-fc9efb0f8b63"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN\n",
        "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision import transforms\n",
        "\n",
        "import torch.utils.data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sRPGEj-rm81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir('../input/global-wheat-detection/test/')\n",
        "\n",
        "test_dir = '../input/global-wheat-detection/test/'\n",
        "train_dir = '../input/global-wheat-detection/train/'\n",
        "\n",
        "test_df = pd.read_csv('../input/global-wheat-detection/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwJFzsZftjjn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e310b360-fd1b-4f8d-9c12-b661a9b9c058"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slj3PpQd2Q7s",
        "colab_type": "text"
      },
      "source": [
        "# Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjiuDhZB2KU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def checkpoints(best_loss, current_loss, epoch, initalization=True):\n",
        "    if initalization:\n",
        "        if epoch < 5:\n",
        "            return max(best_loss, current_loss)\n",
        "\n",
        "    if best_loss > current_loss:\n",
        "        best_loss = current_loss\n",
        "        torch.save(model.state_dict(), f'../input/checkpoints/best{epoch}_{best_loss}.pth')\n",
        "    return best_loss\n",
        "\n",
        "def earlyStopping(best_loss, current_loss, cnt, threshold=10):\n",
        "    flag = False\n",
        "    if best_loss < current_loss:\n",
        "        cnt += 1\n",
        "    else:\n",
        "        cnt = 0\n",
        "\n",
        "    if cnt >= threshold:\n",
        "        flag = True\n",
        "    return cnt, flag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEHFd7y4svNE",
        "colab_type": "text"
      },
      "source": [
        "# DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8J2RpK7tA1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_transform():\n",
        "  list_transforms = []\n",
        "  list_transforms.append(transforms.ToTensor())\n",
        "  return transforms.Compose(list_transforms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg7ZeJwo5e7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PsuedoWheat(torch.utils.data.Dataset):\n",
        "  def __init__(self, input_df, input_dir, transforms=None):\n",
        "    \n",
        "    self.df = input_df\n",
        "    self.list_images = list(self.df['image_id'].unique())\n",
        "    self.image_dir = input_dir\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_id = self.list_images[idx]\n",
        "\n",
        "    img = cv2.imread(self.image_dir + '/' + img_id + '.jpg')\n",
        "    im_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img_scaled = img / 255.\n",
        "    img_final = img_scaled\n",
        "\n",
        "    if self.transforms is not None:\n",
        "      img_final = self.transforms(img_final)\n",
        "\n",
        "    return img_final, img_id\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df['image_id'].unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dVoxPYHuRHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GlobalWheatDetectionDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, input_df, input_dir, transforms=None):\n",
        "\n",
        "    self.df = input_df\n",
        "    self.list_images = list(self.df['image_id'].unique())\n",
        "    self.image_dir = input_dir\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    cols_to_be_selected = ['x_min', 'y_min', 'x_max', 'y_max']\n",
        "    img_id = self.list_images[idx]\n",
        "    bboxes_array = np.array(self.df.loc[self.df['image_id'] == img_id, cols_to_be_selected])\n",
        "    boxes = torch.tensor(bboxes_array, dtype=torch.int64)\n",
        "\n",
        "    num_boxes = self.df.loc[self.df['image_id'] == img_id].shape[0]\n",
        "    labels = torch.ones(num_boxes, dtype=torch.int64)\n",
        "\n",
        "    area = torch.tensor(np.array(self.df['area']), dtype=torch.int64)\n",
        "\n",
        "    iscrowd = torch.zeros(num_boxes, dtype=torch.uint8)\n",
        "\n",
        "    target = {}\n",
        "    target['boxes'] = boxes\n",
        "    target['labels'] = labels\n",
        "    target['area'] = area\n",
        "    target['iscrowd'] = iscrowd\n",
        "\n",
        "    if 'nvnn' in img_id:\n",
        "      img_id = img_id[4:]\n",
        "      img = cv2.imread(f'{test_dir}/{img_id}.jpg')\n",
        "    else:\n",
        "      img = cv2.imread(f'{self.image_dir}/{img_id}.jpg')\n",
        "    img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img_scaled = img_RGB / 255.\n",
        "    img_final = img_scaled\n",
        "\n",
        "    if self.transforms is not None:\n",
        "      img_final = self.transforms(img_final)\n",
        "\n",
        "    return img_final, target, img_id\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.df['image_id'].unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kRSpCuPwend",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = PsuedoWheat(test_df, test_dir, get_transform())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5ctscnb1Qnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_fn(batch):\n",
        "  return tuple(zip(*batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MWRvMom1kZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = 2,\n",
        "    shuffle = False,\n",
        "    num_workers = 4,\n",
        "    collate_fn = collate_fn\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqQcZjn02eGg",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpI0cigi2fJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fasterrcnn_fpn(pretrained=False, progress=True,\n",
        "                   num_classes=2, pretrained_backbone=True,\n",
        "                   trainable_backbone_layers=3, **kwargs):\n",
        "  assert trainable_backbone_layers <= 5 and trainable_backbone_layers >= 0\n",
        "  if not (pretrained or pretrained_backbone):\n",
        "    trainable_backbone_layers = 5\n",
        "  if pretrained:\n",
        "    pretrained_backbone = False\n",
        "  backbone = resnet_fpn_backbone('resnet152', pretrained_backbone)\n",
        "  model = FasterRCNN(backbone, num_classes, **kwargs)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vBRbNRh3SKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_model(pretrained):\n",
        "  model = fasterrcnn_fpn(pretrained=pretrained)\n",
        "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUS4RzVo3jTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = initialize_model(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DZeBunz3m3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saved_model_path = '../input/fasterrcnn/FasterRCNN_ResNet152_FPN_Best_49epoch.pth'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUI4zCKw4Uwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca50ac7b-951f-4334-f47a-5e468cd6d010"
      },
      "source": [
        "model.load_state_dict(torch.load(saved_model_path))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BZldLcs4ZbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6f76a50f-e513-4e38-abb0-f55dc43c672f"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d()\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d()\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d()\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (6): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (7): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d()\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (6): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (7): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (8): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (9): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (10): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (11): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (12): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (13): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (14): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (15): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (16): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (17): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (18): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (19): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (20): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (21): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (22): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (23): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (24): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (25): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (26): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (27): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (28): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (29): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (30): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (31): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (32): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (33): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (34): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (35): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d()\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign()\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCr-xsQk4ezR",
        "colab_type": "text"
      },
      "source": [
        "# Make Pseudo labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxiG5wUM484U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_prediction_string(boxes, scores):\n",
        "  pred_strings = []\n",
        "  for j in zip(scores, boxes):\n",
        "    pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n",
        "    return \" \".join(pred_strings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dloelPa34krE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detection_threshold = 0.5\n",
        "results = []\n",
        "testdf_psuedo = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIZGoeUm5NBR",
        "colab_type": "code",
        "outputId": "b404a11f-ea44-42e4-89ff-825e4ad9d6a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "for images, image_ids in test_dataloader:\n",
        "  \n",
        "  images = list(image.to(device, dtype=torch.float) for image in images)\n",
        "  outputs = model(images)\n",
        "  \n",
        "  for i, image in enumerate(images):\n",
        "    boxes = outputs[i]['boxes'].data.cpu().numpy()\n",
        "    scores = outputs[i]['scores'].data.cpu().numpy()\n",
        "\n",
        "    boxes = boxes[scores >= detection_threshold].astype(np.int32)\n",
        "    scores = scores[scores >= detection_threshold]\n",
        "\n",
        "    image_id = image_ids[i]\n",
        "\n",
        "    boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
        "    boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
        "    \n",
        "    for box in boxes:\n",
        "      result = {\n",
        "          'image_id': 'nvnn'+image_id,\n",
        "          'x_min': box[0],\n",
        "          'y_min': box[1],\n",
        "          'x_max': box[0] + box[2],\n",
        "          'y_max': box[1] + box[3],\n",
        "          'width': box[2],\n",
        "          'height': box[3],\n",
        "          'area': box[2] * box[3],\n",
        "          'source': 'nvnn',\n",
        "      }\n",
        "      testdf_psuedo.append(result)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero(Tensor input, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(Tensor input, *, bool as_tuple)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKBfuyz-_R_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c84d7425-c042-4b18-a12f-4c45a75f26e5"
      },
      "source": [
        "test_df_psuedo = pd.DataFrame(testdf_psuedo,\n",
        "                              columns=['image_id', 'x_min', 'y_min',\n",
        "                                       'x_max', 'y_max', 'width',\n",
        "                                       'height', 'area', 'source'])\n",
        "test_df_psuedo.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>x_min</th>\n",
              "      <th>y_min</th>\n",
              "      <th>x_max</th>\n",
              "      <th>y_max</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>area</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nvnnaac893a91</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>176</td>\n",
              "      <td>158</td>\n",
              "      <td>115</td>\n",
              "      <td>158</td>\n",
              "      <td>18170</td>\n",
              "      <td>nvnn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nvnnaac893a91</td>\n",
              "      <td>612</td>\n",
              "      <td>917</td>\n",
              "      <td>696</td>\n",
              "      <td>1020</td>\n",
              "      <td>84</td>\n",
              "      <td>103</td>\n",
              "      <td>8652</td>\n",
              "      <td>nvnn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nvnnaac893a91</td>\n",
              "      <td>738</td>\n",
              "      <td>769</td>\n",
              "      <td>817</td>\n",
              "      <td>887</td>\n",
              "      <td>79</td>\n",
              "      <td>118</td>\n",
              "      <td>9322</td>\n",
              "      <td>nvnn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nvnnaac893a91</td>\n",
              "      <td>692</td>\n",
              "      <td>381</td>\n",
              "      <td>819</td>\n",
              "      <td>557</td>\n",
              "      <td>127</td>\n",
              "      <td>176</td>\n",
              "      <td>22352</td>\n",
              "      <td>nvnn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nvnnaac893a91</td>\n",
              "      <td>329</td>\n",
              "      <td>660</td>\n",
              "      <td>449</td>\n",
              "      <td>810</td>\n",
              "      <td>120</td>\n",
              "      <td>150</td>\n",
              "      <td>18000</td>\n",
              "      <td>nvnn</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        image_id  x_min  y_min  x_max  y_max  width  height   area source\n",
              "0  nvnnaac893a91     61      0    176    158    115     158  18170   nvnn\n",
              "1  nvnnaac893a91    612    917    696   1020     84     103   8652   nvnn\n",
              "2  nvnnaac893a91    738    769    817    887     79     118   9322   nvnn\n",
              "3  nvnnaac893a91    692    381    819    557    127     176  22352   nvnn\n",
              "4  nvnnaac893a91    329    660    449    810    120     150  18000   nvnn"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLRqGhxh_eiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('../input/global-wheat-detection/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG5ozxG_FoYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df[train_df['height'] > 10]\n",
        "train_df = train_df[train_df['width'] > 10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcMqyOHzFr62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frames = [train_df, test_df_psuedo]\n",
        "\n",
        "train_df = pd.concat(frames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeDeOChpGALv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mroCq3UIGggZ",
        "colab_type": "text"
      },
      "source": [
        "# DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e8hNZQfHGpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_percentage = 0.2\n",
        "np.random.seed(1524)\n",
        "list_val_imageid = np.random.choice(np.array(train_df['image_id'].unique()),\n",
        "                 int(len(train_df['image_id'].unique()) * val_percentage))\n",
        "list_train_imageid = np.setdiff1d(np.array(train_df['image_id'].unique()), list_val_imageid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhyeZzKIHYuC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "16024a0b-9ce2-4638-a6ff-e7e92ed4d2aa"
      },
      "source": [
        "print('Number of validation images: ', len(list_val_imageid))\n",
        "print('Number of training images: ', len(list_train_imageid))\n",
        "print('Number of total images: ', len(train_df['image_id'].unique()))\n",
        "print('Check: ', len(train_df['image_id'].unique()) == len(list_val_imageid) + len(list_train_imageid))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of validation images:  1351\n",
            "Number of training images:  5550\n",
            "Number of total images:  6755\n",
            "Check:  False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vYeEy_4OC1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_val = train_df.loc[train_df['image_id'].isin(list_val_imageid), :]\n",
        "df_train = train_df.loc[train_df['image_id'].isin(list_train_imageid), :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlVNnX7ZWeOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = GlobalWheatDetectionDataset(df_train, train_dir, get_transform())\n",
        "val_dataset = GlobalWheatDetectionDataset(df_val, train_dir, get_transform())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJh1GK7WYXAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = 8,\n",
        "    shuffle = True,\n",
        "    num_workers = 4,\n",
        "    collate_fn = collate_fn\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size = 8,\n",
        "    shuffle = False,\n",
        "    num_workers = 4,\n",
        "    collate_fn = collate_fn\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5dQQWcBYske",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJB1VbFnY0Kp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.00005, max_lr=0.005)\n",
        "num_epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ObFUYR2ZLwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "itr = 1\n",
        "best_loss = np.float('inf')\n",
        "flag = False\n",
        "cnt = 0\n",
        "hist_train_loss = []\n",
        "hist_val_loss = []\n",
        "initial_epoch = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etdo5Gtgfd5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(initial_epoch, num_epochs + 1):\n",
        "  model.train()\n",
        "  loss_sum = 0\n",
        "  num_iterations = 0\n",
        "  for images, targets, image_ids in tqdm(train_dataloader):\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
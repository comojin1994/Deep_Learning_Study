{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dfd37a3",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cbbf4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import os, random, math\n",
    "\n",
    "from tqdm import tqdm\n",
    "from easydict import EasyDict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.io as sio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cea641",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9ac63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_log(inputs: str):\n",
    "    print(f'LOG >>> {inputs}')\n",
    "\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    print_log('Complete seed setting!!!')\n",
    "    \n",
    "    \n",
    "def get_device(GPU_NUM: str) -> torch.device:\n",
    "    if torch.cuda.is_available() > 1:\n",
    "        output = torch.device('cuda')\n",
    "    elif torch.cuda.is_available() == 1:\n",
    "        output = torch.device(f'cuda:{GPU_NUM}')\n",
    "    else:\n",
    "        output = torch.device('cpu')\n",
    "\n",
    "    print_log(f'{output} is checked')\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_log_name(**kwargs):\n",
    "    output = kwargs['time']\n",
    "    \n",
    "    for key in kwargs.keys():\n",
    "        if key == 'time' or key == 'etc': continue\n",
    "        output += f'_{key}_{kwargs[key]}'\n",
    "    \n",
    "    if 'etc' in kwargs.keys():\n",
    "        if kwargs['etc'] != None:\n",
    "            output = output + '_' + kwargs['etc']\n",
    "\n",
    "    print_log(f'Log name: \\n\\t{output}')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "977df73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG >>> cuda:0 is checked\n",
      "LOG >>> Complete seed setting!!!\n",
      "LOG >>> Log name: \n",
      "\t20210708-062959_batch_32_lr_0.001_loss_MAE_optimizer_adam_lr_scheduler_CosineAnnealingWarmRestarts\n"
     ]
    }
   ],
   "source": [
    "args = EasyDict({\n",
    "    #### Path ####\n",
    "    'BASE_PATH': f'../Datasets/Programmers',\n",
    "    'CKPT_PATH': './checkpoints',\n",
    "    'LOG_PATH': './logs',\n",
    "    \n",
    "    \n",
    "    #### Setting ####\n",
    "    'SEED': 42,\n",
    "    'GPU_NUM': '0',\n",
    "    'current_time': datetime.now().strftime('%Y%m%d-%H%M%S'),\n",
    "    'num_workers': 6,\n",
    "    'k_folds': 5,\n",
    "    \n",
    "    \n",
    "    #### Training step ####\n",
    "    'EPOCHS': 5,\n",
    "    'early_stop': 0,\n",
    "    'warmup': 0,\n",
    "    'batch_size': 32,\n",
    "    'lr': 1e-3,\n",
    "    'loss': 'MAE',\n",
    "    'optimizer': 'adam',\n",
    "    'lr_scheduler': 'CosineAnnealingWarmRestarts',\n",
    "    \n",
    "    \n",
    "    #### ETC ####\n",
    "    'log_etc': None,\n",
    "    'is_save': False,\n",
    "    'use_SAM': False,\n",
    "})\n",
    "\n",
    "\n",
    "#### Set Device ####\n",
    "if torch.cuda.is_available():\n",
    "    os.environ['CUDA_VISIBLE_DEVBICES'] = args.GPU_NUM\n",
    "args['device'] = get_device(args.GPU_NUM)\n",
    "cudnn.benchmark = True\n",
    "cudnn.fastest = True\n",
    "\n",
    "\n",
    "#### Set SEED ####\n",
    "seed_everything(args.SEED)\n",
    "\n",
    "\n",
    "#### Log setting ####\n",
    "log_list = {\n",
    "    'time': args.current_time,\n",
    "    'batch': args.batch_size,\n",
    "    'lr': args.lr,\n",
    "    'loss': args.loss,\n",
    "    'optimizer': args.optimizer,\n",
    "    'lr_scheduler': args.lr_scheduler,\n",
    "    'etc': args.log_etc,\n",
    "}\n",
    "\n",
    "args['LOG_NAME'] = get_log_name(**log_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e272a68c",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b623ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "        dataset = Dataset(args, is_train=True)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 args,\n",
    "                 is_train):\n",
    "        \n",
    "        self.args = args\n",
    "        self.path = args.BASE_PATH\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        self.init_data()\n",
    "        self.init_transform()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \n",
    "        sample = {\n",
    "            'image': train_image,\n",
    "            'label': label_image\n",
    "        }\n",
    "        \n",
    "        if self.transforms:\n",
    "            sample = self.transforms(**sample)\n",
    "            b\n",
    "        # targets['image'] = self.transforms(image=targets['image'])['image']\n",
    "        # targets['label'] = self.transforms(label=targets['label'])['image']\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    def init_data(self):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def init_transform(self):\n",
    "        \n",
    "        if self.is_train:\n",
    "            self.transforms = A.Compose([\n",
    "                A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), p=1.0),\n",
    "                ToTensorV2(p=1.0)\n",
    "            ])\n",
    "        else:\n",
    "            self.transforms = A.Compose([\n",
    "                A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), p=1.0),\n",
    "                ToTensorV2(p=1.0)\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213ae570",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(args, is_train=True)\n",
    "test_dataset = Dataset(args, is_train=False)\n",
    "\n",
    "test_dataloader = DataLoader(train_dataset,\n",
    "                             batch_size=1,\n",
    "                             shuffle=False,\n",
    "                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b65f37c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee04e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, 3, 3, padding='same')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4025ecf5",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self, mode):\n",
    "        self.mode = mode\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.value = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.avg = 0\n",
    "    \n",
    "    def update(self, value, batch_size):\n",
    "        if self.mode == 'loss':\n",
    "            self.value = value\n",
    "            self.sum += value * batch_size\n",
    "            self.count += batch_size\n",
    "            self.avg = self.sum / self.count\n",
    "        elif self.mode == 'acc':\n",
    "            self.value = value\n",
    "            self.sum += value\n",
    "            self.count += batch_size\n",
    "            self.avg = self.sum / self.count\n",
    "            \n",
    "            \n",
    "class EarlyStopping(object):\n",
    "    def __init__(self, mode, ckpt_path, filename, is_save=False, early_stop_threshold=10):\n",
    "        # mode: str, 최소, 최대 모드 설정 ex. min, max\n",
    "        # ckpt_path: str, 체크포인트 저장 경로\n",
    "        # early_stop_threshold: int, 얼리스탑 기준, ex. 10\n",
    "        self.mode = mode\n",
    "        if not os.path.exists(ckpt_path):\n",
    "            os.makedirs(ckpt_path)\n",
    "        self.ckpt_path = ckpt_path + '/' + filename\n",
    "        self.is_save = is_save\n",
    "        self.early_stop_threshold = early_stop_threshold\n",
    "        self.best_model = None\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.early_stop_cnt = 0\n",
    "        self.best_score = math.inf if self.mode == 'min' else -math.inf\n",
    "        \n",
    "    def update(self, val, model):\n",
    "        if self.mode == 'min':\n",
    "            if self.best_score > val:\n",
    "                self.early_stop_cnt = 0\n",
    "                self.best_score = val\n",
    "                if self.is_save:\n",
    "                    torch.save(model.state_dict(), self.ckpt_path)\n",
    "                self.best_model = model\n",
    "            else:\n",
    "                self.early_stop_cnt += 1\n",
    "        elif self.mode == 'max':\n",
    "            if self.best_score < val:\n",
    "                self.early_stop_cnt = 0\n",
    "                self.best_score = val\n",
    "                if self.is_save:\n",
    "                    torch.save(model.state_dict(), self.ckpt_path)\n",
    "                self.best_model = model\n",
    "            else:\n",
    "                self.early_stop_cnt += 1\n",
    "        else:\n",
    "            raise Exception('Wrong Input! plz input min or max')\n",
    "        \n",
    "        if self.early_stop_cnt > self.early_stop_threshold:\n",
    "            print_log('Early stopping')\n",
    "            return True, self.best_model\n",
    "        else:\n",
    "            return False, self.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d30b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                e_w = p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "                self.state[p][\"e_w\"] = e_w\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.sub_(self.state[p][\"e_w\"])  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "                    torch.stack([\n",
    "                        p.grad.norm(p=2).to(shared_device)\n",
    "                        for group in self.param_groups for p in group[\"params\"]\n",
    "                        if p.grad is not None\n",
    "                    ]),\n",
    "                    p=2\n",
    "               )\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca91f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criterion(name):\n",
    "    if name == 'MAE':\n",
    "        criterion = torch.nn.L1Loss()\n",
    "    elif name == 'MSE':\n",
    "        criterion = torch.nn.MSELoss()\n",
    "    elif name == 'PSNR':\n",
    "        criterion = PSNR()\n",
    "    else:\n",
    "        raise Exception('Wrong Input! plz input correct name')\n",
    "    return criterion\n",
    "\n",
    "\n",
    "def get_optimizer(name, model, args):\n",
    "    if name == 'sgd':\n",
    "        optimizer = optim.SGD\n",
    "        optimizer = SAM(model.parameters(), optimizer, lr=args.lr, momentum=args.momentum)\n",
    "    elif name == 'adam':\n",
    "        # optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "        optimizer = optim.Adam\n",
    "        optimizer = SAM(model.parameters(), optimizer, lr=args.lr)\n",
    "    elif name == 'adamw':\n",
    "        optimizer = optim.AdamW\n",
    "        optimizer = SAM(model.parameters(), optimizer, lr=args.lr)\n",
    "    elif name == 'rmsprop':\n",
    "        optimizer = optim.RMSprop\n",
    "        optimizer = SAM(model.parameters(), optimizer, lr=args.lr, momentum=args.momentum)\n",
    "    else:\n",
    "        raise Exception('Wrong Input! plz input correct name')\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def get_scheduler(name, optimizer, args):\n",
    "    if name == 'StepLR':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif name == 'CosineAnnealingLR':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.EPOCHS//10, eta_min=0)\n",
    "    elif name == 'CyclicLR':\n",
    "        try:\n",
    "            scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr=args.lr /10, max_lr=args.lr, step_size_up=args.EPOCHS//5, mode=\"triangular2\")\n",
    "        except ValueError:\n",
    "            scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr=args.lr/10, max_lr=args.lr, step_size_up=args.EPOCHS//5, cycle_momentum=False, mode=\"triangular2\")\n",
    "    elif name == 'OneCycleLR':\n",
    "        try:\n",
    "            scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=args.lr, steps_per_epoch=1, epochs=args.EPOCHS)\n",
    "        except ValueError:\n",
    "            scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=args.lr, steps_per_epoch=1, epochs=args.EPOCHS, cycle_momentum=False)\n",
    "    elif name == 'CosineAnnealingWarmRestarts':\n",
    "        # scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=1, eta_min=args.lr//10, last_epoch=-1)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-10, last_epoch=-1)\n",
    "    elif name == 'CosineAnnealingWarmUpRestarts':\n",
    "        scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=10, T_mult=2, eta_max=args.lr, T_up=5, gamma=1.0)\n",
    "    else:\n",
    "        raise Exception('Wrong Input! plz input correct name')\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda02f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=args.k_folds, shuffle=True, random_state=args.SEED)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)):\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  pin_memory=True,\n",
    "                                  sampler=train_subsampler)\n",
    "    val_dataloader = DataLoader(train_dataset,\n",
    "                                batch_size=args.batch_size,\n",
    "                                pin_memory=True,\n",
    "                                sampler=val_subsampler)\n",
    "    dataloaders = {'train': train_dataloader, 'val': val_dataloader}\n",
    "    \n",
    "    break_point = False\n",
    "    \n",
    "    model = Net()\n",
    "    model.to(args.device)\n",
    "\n",
    "    criterion = get_criterion(args.loss)\n",
    "    optimizer = get_optimizer(args.optimizer, model, args)\n",
    "    scheduler = get_scheduler(args.lr_scheduler, optimizer, args)\n",
    "    \n",
    "    ### Logging setting ###\n",
    "    print(f'LOG >>> \\n\\tBatch size: {args.batch_size}\\n\\tLR: {args.lr}\\n\\tOptimizer: {args.optimizer}\\n\\tScheduler: {args.lr_scheduler}\\n')\n",
    "\n",
    "    writer = SummaryWriter(f'{args.LOG_PATH}/{args.LOG_NAME}')\n",
    "\n",
    "\n",
    "    ### Early stopping setting ###\n",
    "    early_stopping = EarlyStopping(mode='min',\n",
    "                                   ckpt_path=f'{args.CKPT_PATH}/{args.LOG_NAME}_fold{fold+1}/',\n",
    "                                   filename=f'best_model.pth',\n",
    "                                   is_save=args.is_save,\n",
    "                                   early_stop_threshold=args.early_stop)\n",
    "\n",
    "    for epoch in range(args.EPOCHS):\n",
    "\n",
    "        ######################################\n",
    "        ###          Add Metrics           ###\n",
    "        train_loss = AverageMeter(mode='loss')\n",
    "        val_loss = AverageMeter(mode='loss')\n",
    "        ######################################\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train': model.train()\n",
    "            else: model.eval()\n",
    "\n",
    "            with tqdm(dataloaders[phase], total=dataloaders[phase].__len__(), unit='batch') as train_bar:\n",
    "\n",
    "                for sample in train_bar:\n",
    "\n",
    "                    ### Logging ###\n",
    "                    train_bar.set_description(f'{phase} Epoch {epoch}')\n",
    "\n",
    "                    images = sample['image'].to(args.device, dtype=torch.float)\n",
    "                    labels = sample['label'].to(args.device, dtype=torch.float)\n",
    "\n",
    "                    batch_size = images.shape[0]\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            \n",
    "                            if agrs.use_SAM:\n",
    "                                ### SAM ###\n",
    "                                def closure():\n",
    "                                    loss = criterion(model(inputs), labels)\n",
    "                                    loss.backward()\n",
    "                                    return loss\n",
    "                                \n",
    "                                    ####################################\n",
    "                                    '''\n",
    "                                    SAM: Noisy label 해결 기법\n",
    "                                    Sharpness-Aware Minimization for Efficiently Improving Generalization\n",
    "                                    '''\n",
    "                                    optimizer.step(closure)\n",
    "                                    ####################################\n",
    "                            else:\n",
    "                                optimizer.step()\n",
    "                                \n",
    "                            train_loss.update(loss_.detach().item(), batch_size)\n",
    "\n",
    "                        else:\n",
    "                            val_loss.update(loss.detach().item(), batch_size)\n",
    "\n",
    "                    ### Logging ###\n",
    "                    if phase == 'train':\n",
    "                        train_bar.set_postfix(train_loss=train_loss.avg)\n",
    "                    else:\n",
    "                        train_bar.set_postfix(val_loss=val_loss.avg)\n",
    "\n",
    "            if phase == 'val' and epoch >= args.warmup:\n",
    "                break_point, best_model = early_stopping.update(val_loss.avg, model)\n",
    "\n",
    "        ### Tensorboard ###\n",
    "        writer.add_scalar('Loss/train', train_loss.avg, epoch)\n",
    "        writer.add_scalar('Loss/val', val_loss.avg, epoch)\n",
    "\n",
    "        if scheduler is not None: scheduler.step()\n",
    "\n",
    "        if break_point: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304cacd4",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d403b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc01f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_results = []\n",
    "\n",
    "for fold in range(5):\n",
    "    \n",
    "    fold_results = []\n",
    "    \n",
    "    for data in test_dataloader:\n",
    "        data = data.to(args.device).astype('float')\n",
    "\n",
    "        model = torch.load(ckpt_path[fold])\n",
    "        model.eval()\n",
    "        \n",
    "        output = model(data)\n",
    "        output = output.detach().cpu().numpy()\n",
    "        \n",
    "        fold_results.append(output)\n",
    "        \n",
    "    total_results.append(fold_results)\n",
    "    \n",
    "total_results = np.array(total_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
